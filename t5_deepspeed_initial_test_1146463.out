## Current dircectory /home/s1930443/MRP1
## Number of available CUDA devices: 0,1,2,3
## Checking status of CUDA device with nvidia-smi
Sun Mar 12 18:10:24 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 525.60.13    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:5A:00.0 Off |                  N/A |
| 30%   27C    P8    11W / 250W |    252MiB / 11264MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:62:00.0 Off |                  N/A |
| 29%   27C    P8    19W / 250W |    252MiB / 11264MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:B9:00.0 Off |                  N/A |
| 30%   26C    P8    18W / 250W |    252MiB / 11264MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  N/A |
| 29%   24C    P8    21W / 250W |    252MiB / 11264MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
[/bin/bash] #### Starting Initial T5 Training Test
[/bin/bash] ## This is s1930443 on node851 and this job has the ID 1146463
[/bin/bash] ## current working directory: /home/s1930443/MRP1
[/bin/bash] ## Run script
[2023-03-12 18:10:35,535] [WARNING] [runner.py:186:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3: setting --include=localhost:0,1,2,3
[2023-03-12 18:10:35,565] [INFO] [runner.py:548:main] cmd = /data1/s1930443/conda_pkgs/T5-test-env/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None t5_deepspeed_initial.py --deepspeed /home/s1930443/.config/deepspeed/ds_config_zero3.json --dataset_label artsplit --train_articles_filepath /home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv --train_comments_filepath /home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv --val_articles_filepath /home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv --val_comments_filepath /home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv --hf_model_id t5-small --train_batch_size 2 --val_batch_size 2 --train_epochs 1 --val_epochs 1 --learning_rate 0.0001 --seed 42 --max_source_len 512 --max_target_len 200 --wandb_project_name t5-deepspeed-alice-initial-test --deepspeed_config_filepath /home/s1930443/.config/deepspeed/ds_config_zero3.json
[2023-03-12 18:10:46,747] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2023-03-12 18:10:46,748] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=4, node_rank=0
[2023-03-12 18:10:46,748] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2023-03-12 18:10:46,748] [INFO] [launch.py:162:main] dist_world_size=4
[2023-03-12 18:10:46,748] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
Arguments passed to the script:  ['t5_deepspeed_initial.py', '--local_rank=0', '--deepspeed', '/home/s1930443/.config/deepspeed/ds_config_zero3.json', '--dataset_label', 'artsplit', '--train_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', '--train_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', '--val_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', '--val_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', '--hf_model_id', 't5-small', '--train_batch_size', '2', '--val_batch_size', '2', '--train_epochs', '1', '--val_epochs', '1', '--learning_rate', '0.0001', '--seed', '42', '--max_source_len', '512', '--max_target_len', '200', '--wandb_project_name', 't5-deepspeed-alice-initial-test', '--deepspeed_config_filepath', '/home/s1930443/.config/deepspeed/ds_config_zero3.json']
Running script with the following arguments:  {'deepspeed': '/home/s1930443/.config/deepspeed/ds_config_zero3.json', 'dataset_label': 'artsplit', 'train_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', 'train_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', 'val_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', 'val_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', 'hf_model_id': 't5-small', 'train_batch_size': '2', 'val_batch_size': '2', 'train_epochs': '1', 'val_epochs': '1', 'learning_rate': '0.0001', 'seed': '42', 'max_source_len': '512', 'max_target_len': '200', 'wandb_project_name': 't5-deepspeed-alice-initial-test', 'deepspeed_config_filepath': '/home/s1930443/.config/deepspeed/ds_config_zero3.json'}
Arguments passed to the script:  ['t5_deepspeed_initial.py', '--local_rank=3', '--deepspeed', '/home/s1930443/.config/deepspeed/ds_config_zero3.json', '--dataset_label', 'artsplit', '--train_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', '--train_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', '--val_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', '--val_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', '--hf_model_id', 't5-small', '--train_batch_size', '2', '--val_batch_size', '2', '--train_epochs', '1', '--val_epochs', '1', '--learning_rate', '0.0001', '--seed', '42', '--max_source_len', '512', '--max_target_len', '200', '--wandb_project_name', 't5-deepspeed-alice-initial-test', '--deepspeed_config_filepath', '/home/s1930443/.config/deepspeed/ds_config_zero3.json']
Running script with the following arguments:  {'deepspeed': '/home/s1930443/.config/deepspeed/ds_config_zero3.json', 'dataset_label': 'artsplit', 'train_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', 'train_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', 'val_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', 'val_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', 'hf_model_id': 't5-small', 'train_batch_size': '2', 'val_batch_size': '2', 'train_epochs': '1', 'val_epochs': '1', 'learning_rate': '0.0001', 'seed': '42', 'max_source_len': '512', 'max_target_len': '200', 'wandb_project_name': 't5-deepspeed-alice-initial-test', 'deepspeed_config_filepath': '/home/s1930443/.config/deepspeed/ds_config_zero3.json'}
Arguments passed to the script:  ['t5_deepspeed_initial.py', '--local_rank=2', '--deepspeed', '/home/s1930443/.config/deepspeed/ds_config_zero3.json', '--dataset_label', 'artsplit', '--train_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', '--train_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', '--val_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', '--val_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', '--hf_model_id', 't5-small', '--train_batch_size', '2', '--val_batch_size', '2', '--train_epochs', '1', '--val_epochs', '1', '--learning_rate', '0.0001', '--seed', '42', '--max_source_len', '512', '--max_target_len', '200', '--wandb_project_name', 't5-deepspeed-alice-initial-test', '--deepspeed_config_filepath', '/home/s1930443/.config/deepspeed/ds_config_zero3.json']
Running script with the following arguments:  {'deepspeed': '/home/s1930443/.config/deepspeed/ds_config_zero3.json', 'dataset_label': 'artsplit', 'train_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', 'train_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', 'val_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', 'val_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', 'hf_model_id': 't5-small', 'train_batch_size': '2', 'val_batch_size': '2', 'train_epochs': '1', 'val_epochs': '1', 'learning_rate': '0.0001', 'seed': '42', 'max_source_len': '512', 'max_target_len': '200', 'wandb_project_name': 't5-deepspeed-alice-initial-test', 'deepspeed_config_filepath': '/home/s1930443/.config/deepspeed/ds_config_zero3.json'}
Arguments passed to the script:  ['t5_deepspeed_initial.py', '--local_rank=1', '--deepspeed', '/home/s1930443/.config/deepspeed/ds_config_zero3.json', '--dataset_label', 'artsplit', '--train_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', '--train_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', '--val_articles_filepath', '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', '--val_comments_filepath', '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', '--hf_model_id', 't5-small', '--train_batch_size', '2', '--val_batch_size', '2', '--train_epochs', '1', '--val_epochs', '1', '--learning_rate', '0.0001', '--seed', '42', '--max_source_len', '512', '--max_target_len', '200', '--wandb_project_name', 't5-deepspeed-alice-initial-test', '--deepspeed_config_filepath', '/home/s1930443/.config/deepspeed/ds_config_zero3.json']
Running script with the following arguments:  {'deepspeed': '/home/s1930443/.config/deepspeed/ds_config_zero3.json', 'dataset_label': 'artsplit', 'train_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_train_artsplit.csv', 'train_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_train_artsplit.csv', 'val_articles_filepath': '/home/s1930443/MRP1/data/artsplit/r_art_val_artsplit.csv', 'val_comments_filepath': '/home/s1930443/MRP1/data/artsplit/r_cmt_val_artsplit.csv', 'hf_model_id': 't5-small', 'train_batch_size': '2', 'val_batch_size': '2', 'train_epochs': '1', 'val_epochs': '1', 'learning_rate': '0.0001', 'seed': '42', 'max_source_len': '512', 'max_target_len': '200', 'wandb_project_name': 't5-deepspeed-alice-initial-test', 'deepspeed_config_filepath': '/home/s1930443/.config/deepspeed/ds_config_zero3.json'}
11993 11993
11993 11993
11993 11993
11993 11993
100 100
100 100
100 100
100 100
[2023-03-12 18:14:19,938] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-03-12 18:14:27,083] [INFO] [partition_parameters.py:415:__exit__] finished initializing model with 0.08B parameters
Initiating Fine-Tuning for the model on the datasetInitiating Fine-Tuning for the model on the dataset

Initiating Fine-Tuning for the model on the dataset
[2023-03-12 18:14:30,395] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed info: version=0.8.1, git-hash=unknown, git-branch=unknown
Initiating Fine-Tuning for the model on the dataset
[2023-03-12 18:14:30,426] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ninja: no work to do.
Time to load cpu_adam op: 4.076684474945068 seconds
Time to load cpu_adam op: 4.133051633834839 seconds
Time to load cpu_adam op: 4.155081748962402 seconds
Time to load cpu_adam op: 4.146919012069702 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
[2023-03-12 18:14:42,386] [INFO] [logging.py:75:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2023-03-12 18:14:42,395] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-03-12 18:14:42,404] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-03-12 18:14:42,405] [INFO] [logging.py:75:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 3 optimizer
[2023-03-12 18:14:42,733] [INFO] [utils.py:825:see_memory_usage] Stage 3 initialize beginning
[2023-03-12 18:14:42,735] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.12 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:42,736] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.01 GB, percent = 6.1%
[2023-03-12 18:14:42,741] [INFO] [stage3.py:114:__init__] Reduce bucket size 262144
[2023-03-12 18:14:42,741] [INFO] [stage3.py:115:__init__] Prefetch bucket size 235929
ninja: no work to do.
Time to load utils op: 0.5277442932128906 seconds
Time to load utils op: 0.6853010654449463 seconds
Time to load utils op: 0.6748130321502686 seconds
Time to load utils op: 0.6902730464935303 seconds
[2023-03-12 18:14:43,484] [INFO] [utils.py:825:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-03-12 18:14:43,486] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:43,500] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.01 GB, percent = 6.1%
Parameter Offload: Total persistent parameters: 16896 in 34 params
[2023-03-12 18:14:43,846] [INFO] [utils.py:825:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-03-12 18:14:43,862] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:43,863] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.01 GB, percent = 6.1%
[2023-03-12 18:14:44,164] [INFO] [utils.py:825:see_memory_usage] Before creating fp16 partitions
[2023-03-12 18:14:44,166] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:44,167] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.01 GB, percent = 6.1%
[2023-03-12 18:14:44,671] [INFO] [utils.py:825:see_memory_usage] After creating fp16 partitions: 1
[2023-03-12 18:14:44,674] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:44,687] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.43 GB, percent = 6.2%
[2023-03-12 18:14:44,997] [INFO] [utils.py:825:see_memory_usage] Before creating fp32 partitions
[2023-03-12 18:14:45,011] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:45,024] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.43 GB, percent = 6.2%
[2023-03-12 18:14:45,399] [INFO] [utils.py:825:see_memory_usage] After creating fp32 partitions
[2023-03-12 18:14:45,401] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:45,414] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 23.49 GB, percent = 6.2%
[2023-03-12 18:14:45,819] [INFO] [utils.py:825:see_memory_usage] Before initializing optimizer states
[2023-03-12 18:14:45,821] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:45,822] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 24.03 GB, percent = 6.4%
[2023-03-12 18:14:46,537] [INFO] [utils.py:825:see_memory_usage] After initializing optimizer states
[2023-03-12 18:14:46,547] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:46,548] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 24.2 GB, percent = 6.4%
[2023-03-12 18:14:46,549] [INFO] [stage3.py:382:_setup_for_real_optimizer] optimizer state initialized
Time to load utils op: 0.01410984992980957 seconds
Time to load utils op: 0.016392230987548828 seconds
Time to load utils op: 0.016759395599365234 seconds
[2023-03-12 18:14:48,617] [INFO] [utils.py:825:see_memory_usage] After initializing ZeRO optimizer
[2023-03-12 18:14:48,619] [INFO] [utils.py:826:see_memory_usage] MA 0.0 GB         Max_MA 0.12 GB         CA 0.19 GB         Max_CA 0 GB 
[2023-03-12 18:14:48,620] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 24.45 GB, percent = 6.5%
[2023-03-12 18:14:48,620] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2023-03-12 18:14:48,620] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed using client callable to create LR scheduler
[2023-03-12 18:14:48,621] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x2aab5bd669e0>
[2023-03-12 18:14:48,621] [INFO] [logging.py:75:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[[0.9, 0.999]]
[2023-03-12 18:14:48,623] [INFO] [config.py:1009:print] DeepSpeedEngine configuration:
[2023-03-12 18:14:48,624] [INFO] [config.py:1013:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-03-12 18:14:48,624] [INFO] [config.py:1013:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-03-12 18:14:48,624] [INFO] [config.py:1013:print]   amp_enabled .................. False
[2023-03-12 18:14:48,624] [INFO] [config.py:1013:print]   amp_params ................... False
[2023-03-12 18:14:48,625] [INFO] [config.py:1013:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-03-12 18:14:48,625] [INFO] [config.py:1013:print]   bfloat16_enabled ............. False
[2023-03-12 18:14:48,625] [INFO] [config.py:1013:print]   checkpoint_parallel_write_pipeline  False
[2023-03-12 18:14:48,626] [INFO] [config.py:1013:print]   checkpoint_tag_validation_enabled  True
[2023-03-12 18:14:48,626] [INFO] [config.py:1013:print]   checkpoint_tag_validation_fail  False
[2023-03-12 18:14:48,626] [INFO] [config.py:1013:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x2aab5d2ed000>
[2023-03-12 18:14:48,627] [INFO] [config.py:1013:print]   communication_data_type ...... None
[2023-03-12 18:14:48,627] [INFO] [config.py:1013:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-03-12 18:14:48,627] [INFO] [config.py:1013:print]   curriculum_enabled_legacy .... False
[2023-03-12 18:14:48,628] [INFO] [config.py:1013:print]   curriculum_params_legacy ..... False
[2023-03-12 18:14:48,628] [INFO] [config.py:1013:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-03-12 18:14:48,629] [INFO] [config.py:1013:print]   data_efficiency_enabled ...... False
[2023-03-12 18:14:48,629] [INFO] [config.py:1013:print]   dataloader_drop_last ......... False
[2023-03-12 18:14:48,629] [INFO] [config.py:1013:print]   disable_allgather ............ False
[2023-03-12 18:14:48,630] [INFO] [config.py:1013:print]   dump_state ................... False
[2023-03-12 18:14:48,630] [INFO] [config.py:1013:print]   dynamic_loss_scale_args ...... None
[2023-03-12 18:14:48,630] [INFO] [config.py:1013:print]   eigenvalue_enabled ........... False
[2023-03-12 18:14:48,630] [INFO] [config.py:1013:print]   eigenvalue_gas_boundary_resolution  1
[2023-03-12 18:14:48,631] [INFO] [config.py:1013:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-03-12 18:14:48,631] [INFO] [config.py:1013:print]   eigenvalue_layer_num ......... 0
[2023-03-12 18:14:48,631] [INFO] [config.py:1013:print]   eigenvalue_max_iter .......... 100
[2023-03-12 18:14:48,631] [INFO] [config.py:1013:print]   eigenvalue_stability ......... 1e-06
[2023-03-12 18:14:48,632] [INFO] [config.py:1013:print]   eigenvalue_tol ............... 0.01
[2023-03-12 18:14:48,632] [INFO] [config.py:1013:print]   eigenvalue_verbose ........... False
[2023-03-12 18:14:48,632] [INFO] [config.py:1013:print]   elasticity_enabled ........... False
[2023-03-12 18:14:48,632] [INFO] [config.py:1013:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-03-12 18:14:48,633] [INFO] [config.py:1013:print]   fp16_auto_cast ............... None
[2023-03-12 18:14:48,633] [INFO] [config.py:1013:print]   fp16_enabled ................. False
[2023-03-12 18:14:48,633] [INFO] [config.py:1013:print]   fp16_master_weights_and_gradients  False
[2023-03-12 18:14:48,634] [INFO] [config.py:1013:print]   global_rank .................. 0
[2023-03-12 18:14:48,634] [INFO] [config.py:1013:print]   grad_accum_dtype ............. None
[2023-03-12 18:14:48,634] [INFO] [config.py:1013:print]   gradient_accumulation_steps .. 1
[2023-03-12 18:14:48,635] [INFO] [config.py:1013:print]   gradient_clipping ............ 1.0
[2023-03-12 18:14:48,636] [INFO] [config.py:1013:print]   gradient_predivide_factor .... 1.0
[2023-03-12 18:14:48,637] [INFO] [config.py:1013:print]   initial_dynamic_scale ........ 65536
[2023-03-12 18:14:48,637] [INFO] [config.py:1013:print]   load_universal_checkpoint .... False
[2023-03-12 18:14:48,637] [INFO] [config.py:1013:print]   loss_scale ................... 0
[2023-03-12 18:14:48,637] [INFO] [config.py:1013:print]   memory_breakdown ............. False
[2023-03-12 18:14:48,638] [INFO] [config.py:1013:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-03-12 18:14:48,638] [INFO] [config.py:1013:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-03-12 18:14:48,638] [INFO] [config.py:1013:print]   optimizer_legacy_fusion ...... False
[2023-03-12 18:14:48,639] [INFO] [config.py:1013:print]   optimizer_name ............... adamw
[2023-03-12 18:14:48,639] [INFO] [config.py:1013:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}
[2023-03-12 18:14:48,639] [INFO] [config.py:1013:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-03-12 18:14:48,640] [INFO] [config.py:1013:print]   pld_enabled .................. False
[2023-03-12 18:14:48,640] [INFO] [config.py:1013:print]   pld_params ................... False
[2023-03-12 18:14:48,641] [INFO] [config.py:1013:print]   prescale_gradients ........... False
[2023-03-12 18:14:48,641] [INFO] [config.py:1013:print]   scheduler_name ............... None
[2023-03-12 18:14:48,641] [INFO] [config.py:1013:print]   scheduler_params ............. None
[2023-03-12 18:14:48,642] [INFO] [config.py:1013:print]   sparse_attention ............. None
[2023-03-12 18:14:48,642] [INFO] [config.py:1013:print]   sparse_gradients_enabled ..... False
[2023-03-12 18:14:48,642] [INFO] [config.py:1013:print]   steps_per_print .............. 10
[2023-03-12 18:14:48,642] [INFO] [config.py:1013:print]   train_batch_size ............. 8
[2023-03-12 18:14:48,643] [INFO] [config.py:1013:print]   train_micro_batch_size_per_gpu  2
[2023-03-12 18:14:48,643] [INFO] [config.py:1013:print]   use_node_local_storage ....... False
[2023-03-12 18:14:48,643] [INFO] [config.py:1013:print]   wall_clock_breakdown ......... False
[2023-03-12 18:14:48,644] [INFO] [config.py:1013:print]   world_size ................... 4
[2023-03-12 18:14:48,644] [INFO] [config.py:1013:print]   zero_allow_untested_optimizer  False
[2023-03-12 18:14:48,644] [INFO] [config.py:1013:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=262144 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=235929 param_persistence_threshold=5120 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-03-12 18:14:48,645] [INFO] [config.py:1013:print]   zero_enabled ................. True
[2023-03-12 18:14:48,645] [INFO] [config.py:1013:print]   zero_optimization_stage ...... 3
[2023-03-12 18:14:48,645] [INFO] [config.py:998:print_user_config]   json = {
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.9, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 0.0
        }
    }, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "offload_param": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09, 
        "reduce_bucket_size": 2.621440e+05, 
        "stage3_prefetch_bucket_size": 2.359296e+05, 
        "stage3_param_persistence_threshold": 5.120000e+03, 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1.0, 
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 2
}
Time to load utils op: 0.015499591827392578 seconds
{'loss': 14.4888, 'learning_rate': 9.966666666666667e-05, 'epoch': 0.0}
[2023-03-12 18:15:19,917] [INFO] [logging.py:75:log_dist] [Rank 0] step=10, skipped=0, lr=[9.933333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:15:19,919] [INFO] [timer.py:198:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=2.9732411519933892, CurrSamplesPerSec=3.1337419267772533, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 7.5471, 'learning_rate': 9.933333333333334e-05, 'epoch': 0.01}
{'loss': 3.1632, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.01}
[2023-03-12 18:15:46,610] [INFO] [logging.py:75:log_dist] [Rank 0] step=20, skipped=0, lr=[9.866666666666668e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:15:46,624] [INFO] [timer.py:198:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=2.996599479995183, CurrSamplesPerSec=3.0175076862091403, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.9328, 'learning_rate': 9.866666666666668e-05, 'epoch': 0.01}
{'eval_loss': 1.0504778623580933, 'eval_runtime': 7.4748, 'eval_samples_per_second': 13.378, 'eval_steps_per_second': 1.739, 'epoch': 0.01}
{'loss': 1.3315, 'learning_rate': 9.833333333333333e-05, 'epoch': 0.02}
[2023-03-12 18:16:22,010] [INFO] [logging.py:75:log_dist] [Rank 0] step=30, skipped=0, lr=[9.8e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:16:22,012] [INFO] [timer.py:198:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=2.957524772333489, CurrSamplesPerSec=3.081029462320727, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.329, 'learning_rate': 9.8e-05, 'epoch': 0.02}
{'loss': 1.3302, 'learning_rate': 9.766666666666668e-05, 'epoch': 0.02}
[2023-03-12 18:16:48,527] [INFO] [logging.py:75:log_dist] [Rank 0] step=40, skipped=0, lr=[9.733333333333335e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:16:48,541] [INFO] [timer.py:198:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=2.9781879571283443, CurrSamplesPerSec=2.6117073094795176, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.809, 'learning_rate': 9.733333333333335e-05, 'epoch': 0.03}
{'eval_loss': 1.030612826347351, 'eval_runtime': 5.8802, 'eval_samples_per_second': 17.006, 'eval_steps_per_second': 2.211, 'epoch': 0.03}
{'loss': 1.1746, 'learning_rate': 9.7e-05, 'epoch': 0.03}
[2023-03-12 18:17:20,749] [INFO] [logging.py:75:log_dist] [Rank 0] step=50, skipped=0, lr=[9.666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:17:20,751] [INFO] [timer.py:198:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=2.9952785904421915, CurrSamplesPerSec=3.1900636036530576, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7927, 'learning_rate': 9.666666666666667e-05, 'epoch': 0.03}
{'loss': 1.06, 'learning_rate': 9.633333333333335e-05, 'epoch': 0.04}
[2023-03-12 18:17:46,859] [INFO] [logging.py:75:log_dist] [Rank 0] step=60, skipped=0, lr=[9.6e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:17:46,864] [INFO] [timer.py:198:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=3.009906276066656, CurrSamplesPerSec=3.0022044275011055, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7071, 'learning_rate': 9.6e-05, 'epoch': 0.04}
{'eval_loss': 0.9452877044677734, 'eval_runtime': 6.7303, 'eval_samples_per_second': 14.858, 'eval_steps_per_second': 1.932, 'epoch': 0.04}
{'loss': 1.0571, 'learning_rate': 9.566666666666667e-05, 'epoch': 0.04}
[2023-03-12 18:18:20,459] [INFO] [logging.py:75:log_dist] [Rank 0] step=70, skipped=0, lr=[9.533333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:18:20,468] [INFO] [timer.py:198:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=3.0082480873396955, CurrSamplesPerSec=2.9574859595263114, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0575, 'learning_rate': 9.533333333333334e-05, 'epoch': 0.05}
{'loss': 0.7787, 'learning_rate': 9.5e-05, 'epoch': 0.05}
[2023-03-12 18:18:46,763] [INFO] [logging.py:75:log_dist] [Rank 0] step=80, skipped=0, lr=[9.466666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:18:46,764] [INFO] [timer.py:198:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=3.0147018088831503, CurrSamplesPerSec=3.1532593629095995, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7241, 'learning_rate': 9.466666666666667e-05, 'epoch': 0.05}
{'eval_loss': 0.9283570647239685, 'eval_runtime': 6.7584, 'eval_samples_per_second': 14.796, 'eval_steps_per_second': 1.924, 'epoch': 0.05}
{'loss': 1.0608, 'learning_rate': 9.433333333333334e-05, 'epoch': 0.06}
[2023-03-12 18:19:19,843] [INFO] [logging.py:75:log_dist] [Rank 0] step=90, skipped=0, lr=[9.4e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:19:19,844] [INFO] [timer.py:198:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=3.0196840346281246, CurrSamplesPerSec=3.0242254881946855, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0517, 'learning_rate': 9.4e-05, 'epoch': 0.06}
{'loss': 0.8356, 'learning_rate': 9.366666666666668e-05, 'epoch': 0.06}
[2023-03-12 18:19:47,273] [INFO] [logging.py:75:log_dist] [Rank 0] step=100, skipped=0, lr=[9.333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:19:47,287] [INFO] [timer.py:198:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=3.010558615444387, CurrSamplesPerSec=2.3860846280428962, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8939, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.07}
{'eval_loss': 0.9092158675193787, 'eval_runtime': 6.5387, 'eval_samples_per_second': 15.293, 'eval_steps_per_second': 1.988, 'epoch': 0.07}
{'loss': 0.8003, 'learning_rate': 9.300000000000001e-05, 'epoch': 0.07}
[2023-03-12 18:20:20,384] [INFO] [logging.py:75:log_dist] [Rank 0] step=110, skipped=0, lr=[9.266666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:20:20,385] [INFO] [timer.py:198:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=3.013228020037606, CurrSamplesPerSec=2.9250338317641646, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0038, 'learning_rate': 9.266666666666666e-05, 'epoch': 0.07}
{'loss': 0.9067, 'learning_rate': 9.233333333333333e-05, 'epoch': 0.08}
[2023-03-12 18:20:47,109] [INFO] [logging.py:75:log_dist] [Rank 0] step=120, skipped=0, lr=[9.200000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:20:47,111] [INFO] [timer.py:198:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=3.013308716634927, CurrSamplesPerSec=3.1909333545336747, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7376, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.08}
{'eval_loss': 0.8869287967681885, 'eval_runtime': 5.8047, 'eval_samples_per_second': 17.227, 'eval_steps_per_second': 2.24, 'epoch': 0.08}
{'loss': 0.9808, 'learning_rate': 9.166666666666667e-05, 'epoch': 0.08}
[2023-03-12 18:21:19,727] [INFO] [logging.py:75:log_dist] [Rank 0] step=130, skipped=0, lr=[9.133333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:21:19,728] [INFO] [timer.py:198:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=3.012841966638218, CurrSamplesPerSec=3.2578997274211736, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6345, 'learning_rate': 9.133333333333334e-05, 'epoch': 0.09}
{'loss': 0.7347, 'learning_rate': 9.1e-05, 'epoch': 0.09}
[2023-03-12 18:21:46,790] [INFO] [logging.py:75:log_dist] [Rank 0] step=140, skipped=0, lr=[9.066666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:21:46,792] [INFO] [timer.py:198:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=3.010305481432355, CurrSamplesPerSec=3.1353908124532675, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8706, 'learning_rate': 9.066666666666667e-05, 'epoch': 0.09}
{'eval_loss': 0.8849171996116638, 'eval_runtime': 5.7714, 'eval_samples_per_second': 17.327, 'eval_steps_per_second': 2.252, 'epoch': 0.09}
{'loss': 0.6938, 'learning_rate': 9.033333333333334e-05, 'epoch': 0.1}
[2023-03-12 18:22:19,196] [INFO] [logging.py:75:log_dist] [Rank 0] step=150, skipped=0, lr=[9e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:22:19,197] [INFO] [timer.py:198:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=3.011309144876792, CurrSamplesPerSec=3.0693275456480444, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6746, 'learning_rate': 9e-05, 'epoch': 0.1}
{'loss': 0.8464, 'learning_rate': 8.966666666666666e-05, 'epoch': 0.1}
[2023-03-12 18:22:45,717] [INFO] [logging.py:75:log_dist] [Rank 0] step=160, skipped=0, lr=[8.933333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:22:45,731] [INFO] [timer.py:198:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=3.0129113428784575, CurrSamplesPerSec=3.2243882615482, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8336, 'learning_rate': 8.933333333333334e-05, 'epoch': 0.11}
{'eval_loss': 0.8801597356796265, 'eval_runtime': 5.9394, 'eval_samples_per_second': 16.837, 'eval_steps_per_second': 2.189, 'epoch': 0.11}
{'loss': 0.9975, 'learning_rate': 8.900000000000001e-05, 'epoch': 0.11}
[2023-03-12 18:23:18,493] [INFO] [logging.py:75:log_dist] [Rank 0] step=170, skipped=0, lr=[8.866666666666668e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:23:18,500] [INFO] [timer.py:198:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=3.0124276012296085, CurrSamplesPerSec=3.1069355790933355, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7739, 'learning_rate': 8.866666666666668e-05, 'epoch': 0.11}
{'loss': 0.8805, 'learning_rate': 8.833333333333333e-05, 'epoch': 0.12}
[2023-03-12 18:23:46,182] [INFO] [logging.py:75:log_dist] [Rank 0] step=180, skipped=0, lr=[8.800000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:23:46,193] [INFO] [timer.py:198:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=3.006307261675933, CurrSamplesPerSec=3.0423837387163326, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.921, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.12}
{'eval_loss': 0.8823015689849854, 'eval_runtime': 5.9363, 'eval_samples_per_second': 16.845, 'eval_steps_per_second': 2.19, 'epoch': 0.12}
{'loss': 1.0591, 'learning_rate': 8.766666666666668e-05, 'epoch': 0.12}
[2023-03-12 18:24:19,009] [INFO] [logging.py:75:log_dist] [Rank 0] step=190, skipped=0, lr=[8.733333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:24:19,010] [INFO] [timer.py:198:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=3.0059809542589018, CurrSamplesPerSec=3.0272619681947615, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8258, 'learning_rate': 8.733333333333333e-05, 'epoch': 0.13}
{'loss': 1.096, 'learning_rate': 8.7e-05, 'epoch': 0.13}
[2023-03-12 18:24:46,444] [INFO] [logging.py:75:log_dist] [Rank 0] step=200, skipped=0, lr=[8.666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:24:46,445] [INFO] [timer.py:198:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=3.0025334168122213, CurrSamplesPerSec=2.3416386905136592, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6021, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.13}
{'eval_loss': 0.8503317832946777, 'eval_runtime': 5.8965, 'eval_samples_per_second': 16.959, 'eval_steps_per_second': 2.205, 'epoch': 0.13}
{'loss': 0.7685, 'learning_rate': 8.633333333333334e-05, 'epoch': 0.14}
[2023-03-12 18:25:19,404] [INFO] [logging.py:75:log_dist] [Rank 0] step=210, skipped=0, lr=[8.6e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:25:19,405] [INFO] [timer.py:198:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=3.00157270640936, CurrSamplesPerSec=2.314215426998423, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6425, 'learning_rate': 8.6e-05, 'epoch': 0.14}
{'loss': 0.9252, 'learning_rate': 8.566666666666667e-05, 'epoch': 0.14}
[2023-03-12 18:25:46,177] [INFO] [logging.py:75:log_dist] [Rank 0] step=220, skipped=0, lr=[8.533333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:25:46,191] [INFO] [timer.py:198:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=3.0017009249421274, CurrSamplesPerSec=3.154071208299028, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7483, 'learning_rate': 8.533333333333334e-05, 'epoch': 0.15}
{'eval_loss': 0.8501582145690918, 'eval_runtime': 6.5845, 'eval_samples_per_second': 15.187, 'eval_steps_per_second': 1.974, 'epoch': 0.15}
{'loss': 0.7745, 'learning_rate': 8.5e-05, 'epoch': 0.15}
[2023-03-12 18:26:19,077] [INFO] [logging.py:75:log_dist] [Rank 0] step=230, skipped=0, lr=[8.466666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:26:19,079] [INFO] [timer.py:198:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=3.0046257395571896, CurrSamplesPerSec=3.0664726194681124, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8461, 'learning_rate': 8.466666666666667e-05, 'epoch': 0.15}
{'loss': 0.6744, 'learning_rate': 8.433333333333334e-05, 'epoch': 0.16}
[2023-03-12 18:26:46,293] [INFO] [logging.py:75:log_dist] [Rank 0] step=240, skipped=0, lr=[8.4e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:26:46,307] [INFO] [timer.py:198:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=3.0025811737721617, CurrSamplesPerSec=2.89438602956145, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7065, 'learning_rate': 8.4e-05, 'epoch': 0.16}
{'eval_loss': 0.8479571342468262, 'eval_runtime': 6.6446, 'eval_samples_per_second': 15.05, 'eval_steps_per_second': 1.956, 'epoch': 0.16}
{'loss': 0.5725, 'learning_rate': 8.366666666666668e-05, 'epoch': 0.16}
[2023-03-12 18:27:19,773] [INFO] [logging.py:75:log_dist] [Rank 0] step=250, skipped=0, lr=[8.333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:27:19,780] [INFO] [timer.py:198:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=3.0025538520943456, CurrSamplesPerSec=3.024534614448912, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7023, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.17}
{'loss': 1.1526, 'learning_rate': 8.3e-05, 'epoch': 0.17}
[2023-03-12 18:27:46,466] [INFO] [logging.py:75:log_dist] [Rank 0] step=260, skipped=0, lr=[8.266666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:27:46,475] [INFO] [timer.py:198:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=3.003172355029249, CurrSamplesPerSec=3.003331153856309, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8566, 'learning_rate': 8.266666666666667e-05, 'epoch': 0.17}
{'eval_loss': 0.8429263234138489, 'eval_runtime': 6.0333, 'eval_samples_per_second': 16.575, 'eval_steps_per_second': 2.155, 'epoch': 0.17}
{'loss': 0.7395, 'learning_rate': 8.233333333333333e-05, 'epoch': 0.18}
[2023-03-12 18:28:19,306] [INFO] [logging.py:75:log_dist] [Rank 0] step=270, skipped=0, lr=[8.2e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:28:19,307] [INFO] [timer.py:198:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=3.0034479773934346, CurrSamplesPerSec=2.903781478934658, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7437, 'learning_rate': 8.2e-05, 'epoch': 0.18}
{'loss': 0.7545, 'learning_rate': 8.166666666666667e-05, 'epoch': 0.18}
[2023-03-12 18:28:45,879] [INFO] [logging.py:75:log_dist] [Rank 0] step=280, skipped=0, lr=[8.133333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:28:45,881] [INFO] [timer.py:198:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=3.0044364143071554, CurrSamplesPerSec=3.1748044465234853, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8384, 'learning_rate': 8.133333333333334e-05, 'epoch': 0.19}
{'eval_loss': 0.8407660126686096, 'eval_runtime': 6.1778, 'eval_samples_per_second': 16.187, 'eval_steps_per_second': 2.104, 'epoch': 0.19}
{'loss': 0.7256, 'learning_rate': 8.1e-05, 'epoch': 0.19}
[2023-03-12 18:29:19,225] [INFO] [logging.py:75:log_dist] [Rank 0] step=290, skipped=0, lr=[8.066666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:29:19,237] [INFO] [timer.py:198:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=3.0028410695792815, CurrSamplesPerSec=3.111162786988879, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6313, 'learning_rate': 8.066666666666667e-05, 'epoch': 0.19}
{'loss': 0.7781, 'learning_rate': 8.033333333333334e-05, 'epoch': 0.2}
[2023-03-12 18:29:46,409] [INFO] [logging.py:75:log_dist] [Rank 0] step=300, skipped=0, lr=[8e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:29:46,422] [INFO] [timer.py:198:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=3.0015129981128545, CurrSamplesPerSec=2.6881889927793003, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8289, 'learning_rate': 8e-05, 'epoch': 0.2}
{'eval_loss': 0.8396263718605042, 'eval_runtime': 6.0487, 'eval_samples_per_second': 16.533, 'eval_steps_per_second': 2.149, 'epoch': 0.2}
{'loss': 0.9478, 'learning_rate': 7.966666666666666e-05, 'epoch': 0.2}
[2023-03-12 18:30:19,425] [INFO] [logging.py:75:log_dist] [Rank 0] step=310, skipped=0, lr=[7.933333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:30:19,427] [INFO] [timer.py:198:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=3.001309475682138, CurrSamplesPerSec=3.110673336132415, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.66, 'learning_rate': 7.933333333333334e-05, 'epoch': 0.21}
{'loss': 0.6664, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.21}
[2023-03-12 18:30:46,848] [INFO] [logging.py:75:log_dist] [Rank 0] step=320, skipped=0, lr=[7.866666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:30:46,858] [INFO] [timer.py:198:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=2.999287049381501, CurrSamplesPerSec=3.0858043790379153, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.708, 'learning_rate': 7.866666666666666e-05, 'epoch': 0.21}
{'eval_loss': 0.8368017673492432, 'eval_runtime': 5.8517, 'eval_samples_per_second': 17.089, 'eval_steps_per_second': 2.222, 'epoch': 0.21}
{'loss': 1.1759, 'learning_rate': 7.833333333333333e-05, 'epoch': 0.22}
[2023-03-12 18:31:19,961] [INFO] [logging.py:75:log_dist] [Rank 0] step=330, skipped=0, lr=[7.800000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:31:19,962] [INFO] [timer.py:198:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=2.998115803546555, CurrSamplesPerSec=3.1005225746443466, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6455, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.22}
{'loss': 1.1618, 'learning_rate': 7.766666666666667e-05, 'epoch': 0.22}
[2023-03-12 18:31:47,065] [INFO] [logging.py:75:log_dist] [Rank 0] step=340, skipped=0, lr=[7.733333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:31:47,077] [INFO] [timer.py:198:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=2.99728006049865, CurrSamplesPerSec=3.113465877395196, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.1289, 'learning_rate': 7.733333333333333e-05, 'epoch': 0.23}
{'eval_loss': 0.8356633186340332, 'eval_runtime': 5.7799, 'eval_samples_per_second': 17.301, 'eval_steps_per_second': 2.249, 'epoch': 0.23}
{'loss': 0.8424, 'learning_rate': 7.7e-05, 'epoch': 0.23}
[2023-03-12 18:32:19,600] [INFO] [logging.py:75:log_dist] [Rank 0] step=350, skipped=0, lr=[7.666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:32:19,601] [INFO] [timer.py:198:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=2.9976513810429224, CurrSamplesPerSec=3.145606697541726, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7926, 'learning_rate': 7.666666666666667e-05, 'epoch': 0.23}
{'loss': 0.6615, 'learning_rate': 7.633333333333334e-05, 'epoch': 0.24}
[2023-03-12 18:32:47,256] [INFO] [logging.py:75:log_dist] [Rank 0] step=360, skipped=0, lr=[7.6e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:32:47,269] [INFO] [timer.py:198:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=2.9951568918754576, CurrSamplesPerSec=3.1120538270609233, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7009, 'learning_rate': 7.6e-05, 'epoch': 0.24}
{'eval_loss': 0.8372726440429688, 'eval_runtime': 5.7266, 'eval_samples_per_second': 17.462, 'eval_steps_per_second': 2.27, 'epoch': 0.24}
{'loss': 0.7512, 'learning_rate': 7.566666666666667e-05, 'epoch': 0.24}
[2023-03-12 18:33:20,269] [INFO] [logging.py:75:log_dist] [Rank 0] step=370, skipped=0, lr=[7.533333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:33:20,270] [INFO] [timer.py:198:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=2.9939961895146263, CurrSamplesPerSec=3.1580742940730353, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7793, 'learning_rate': 7.533333333333334e-05, 'epoch': 0.25}
{'loss': 0.8385, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.25}
[2023-03-12 18:33:47,469] [INFO] [logging.py:75:log_dist] [Rank 0] step=380, skipped=0, lr=[7.466666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:33:47,470] [INFO] [timer.py:198:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=2.9930909961036924, CurrSamplesPerSec=2.6848109778662375, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7128, 'learning_rate': 7.466666666666667e-05, 'epoch': 0.25}
{'eval_loss': 0.834672749042511, 'eval_runtime': 5.9885, 'eval_samples_per_second': 16.699, 'eval_steps_per_second': 2.171, 'epoch': 0.25}
{'loss': 0.7839, 'learning_rate': 7.433333333333333e-05, 'epoch': 0.26}
[2023-03-12 18:34:20,819] [INFO] [logging.py:75:log_dist] [Rank 0] step=390, skipped=0, lr=[7.4e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:34:20,820] [INFO] [timer.py:198:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=2.991899561631474, CurrSamplesPerSec=2.865316243445761, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6504, 'learning_rate': 7.4e-05, 'epoch': 0.26}
{'loss': 0.7206, 'learning_rate': 7.366666666666668e-05, 'epoch': 0.26}
[2023-03-12 18:34:47,439] [INFO] [logging.py:75:log_dist] [Rank 0] step=400, skipped=0, lr=[7.333333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:34:47,453] [INFO] [timer.py:198:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=2.992630355748381, CurrSamplesPerSec=2.7259297868864434, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0034, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.27}
{'eval_loss': 0.8333581686019897, 'eval_runtime': 6.7742, 'eval_samples_per_second': 14.762, 'eval_steps_per_second': 1.919, 'epoch': 0.27}
{'loss': 0.6682, 'learning_rate': 7.3e-05, 'epoch': 0.27}
[2023-03-12 18:35:20,618] [INFO] [logging.py:75:log_dist] [Rank 0] step=410, skipped=0, lr=[7.266666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:35:20,620] [INFO] [timer.py:198:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=2.993904279020185, CurrSamplesPerSec=3.0089731780316398, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8517, 'learning_rate': 7.266666666666667e-05, 'epoch': 0.27}
{'loss': 0.901, 'learning_rate': 7.233333333333335e-05, 'epoch': 0.28}
[2023-03-12 18:35:46,966] [INFO] [logging.py:75:log_dist] [Rank 0] step=420, skipped=0, lr=[7.2e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:35:46,967] [INFO] [timer.py:198:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=2.9953240827228433, CurrSamplesPerSec=3.081393039138808, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0512, 'learning_rate': 7.2e-05, 'epoch': 0.28}
{'eval_loss': 0.8330971598625183, 'eval_runtime': 6.61, 'eval_samples_per_second': 15.129, 'eval_steps_per_second': 1.967, 'epoch': 0.28}
{'loss': 0.7378, 'learning_rate': 7.166666666666667e-05, 'epoch': 0.28}
[2023-03-12 18:36:20,809] [INFO] [logging.py:75:log_dist] [Rank 0] step=430, skipped=0, lr=[7.133333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:36:20,824] [INFO] [timer.py:198:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=2.9943587774241536, CurrSamplesPerSec=2.976058532004457, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7162, 'learning_rate': 7.133333333333334e-05, 'epoch': 0.29}
{'loss': 0.7289, 'learning_rate': 7.1e-05, 'epoch': 0.29}
[2023-03-12 18:36:47,950] [INFO] [logging.py:75:log_dist] [Rank 0] step=440, skipped=0, lr=[7.066666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:36:47,952] [INFO] [timer.py:198:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=2.9937453951468536, CurrSamplesPerSec=3.082497027459813, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6613, 'learning_rate': 7.066666666666667e-05, 'epoch': 0.29}
{'eval_loss': 0.8307138681411743, 'eval_runtime': 5.9437, 'eval_samples_per_second': 16.825, 'eval_steps_per_second': 2.187, 'epoch': 0.29}
{'loss': 0.6654, 'learning_rate': 7.033333333333334e-05, 'epoch': 0.3}
[2023-03-12 18:37:20,543] [INFO] [logging.py:75:log_dist] [Rank 0] step=450, skipped=0, lr=[7e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:37:20,545] [INFO] [timer.py:198:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=2.9944658220797473, CurrSamplesPerSec=3.080446786641642, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7855, 'learning_rate': 7e-05, 'epoch': 0.3}
{'loss': 0.6241, 'learning_rate': 6.966666666666668e-05, 'epoch': 0.3}
[2023-03-12 18:37:47,180] [INFO] [logging.py:75:log_dist] [Rank 0] step=460, skipped=0, lr=[6.933333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:37:47,190] [INFO] [timer.py:198:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=2.9950649657823756, CurrSamplesPerSec=2.969911556121038, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6652, 'learning_rate': 6.933333333333334e-05, 'epoch': 0.31}
{'eval_loss': 0.8307204246520996, 'eval_runtime': 5.9336, 'eval_samples_per_second': 16.853, 'eval_steps_per_second': 2.191, 'epoch': 0.31}
{'loss': 0.6663, 'learning_rate': 6.9e-05, 'epoch': 0.31}
[2023-03-12 18:38:20,644] [INFO] [logging.py:75:log_dist] [Rank 0] step=470, skipped=0, lr=[6.866666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:38:20,645] [INFO] [timer.py:198:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=2.993550639746128, CurrSamplesPerSec=2.875874701104953, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6339, 'learning_rate': 6.866666666666666e-05, 'epoch': 0.31}
{'loss': 0.5384, 'learning_rate': 6.833333333333333e-05, 'epoch': 0.32}
[2023-03-12 18:38:47,226] [INFO] [logging.py:75:log_dist] [Rank 0] step=480, skipped=0, lr=[6.800000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:38:47,233] [INFO] [timer.py:198:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=2.994276254784989, CurrSamplesPerSec=3.1081918243028124, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6885, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.32}
{'eval_loss': 0.8304301500320435, 'eval_runtime': 6.1725, 'eval_samples_per_second': 16.201, 'eval_steps_per_second': 2.106, 'epoch': 0.32}
{'loss': 0.6483, 'learning_rate': 6.766666666666667e-05, 'epoch': 0.32}
[2023-03-12 18:39:20,064] [INFO] [logging.py:75:log_dist] [Rank 0] step=490, skipped=0, lr=[6.733333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:39:20,076] [INFO] [timer.py:198:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=2.9949489821785544, CurrSamplesPerSec=3.1103247287747218, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9696, 'learning_rate': 6.733333333333333e-05, 'epoch': 0.33}
{'loss': 0.7624, 'learning_rate': 6.7e-05, 'epoch': 0.33}
[2023-03-12 18:39:47,081] [INFO] [logging.py:75:log_dist] [Rank 0] step=500, skipped=0, lr=[6.666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:39:47,088] [INFO] [timer.py:198:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=2.9946221162774758, CurrSamplesPerSec=2.7754864359090416, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7072, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.33}
{'eval_loss': 0.830070972442627, 'eval_runtime': 6.2369, 'eval_samples_per_second': 16.033, 'eval_steps_per_second': 2.084, 'epoch': 0.33}
{'loss': 0.7961, 'learning_rate': 6.633333333333334e-05, 'epoch': 0.34}
[2023-03-12 18:40:20,139] [INFO] [logging.py:75:log_dist] [Rank 0] step=510, skipped=0, lr=[6.6e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:40:20,153] [INFO] [timer.py:198:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=2.9948527399470644, CurrSamplesPerSec=2.983335095239395, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8675, 'learning_rate': 6.6e-05, 'epoch': 0.34}
{'loss': 0.7576, 'learning_rate': 6.566666666666666e-05, 'epoch': 0.34}
[2023-03-12 18:40:47,404] [INFO] [logging.py:75:log_dist] [Rank 0] step=520, skipped=0, lr=[6.533333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:40:47,416] [INFO] [timer.py:198:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=2.9940702703977604, CurrSamplesPerSec=2.9889429064383126, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8506, 'learning_rate': 6.533333333333334e-05, 'epoch': 0.35}
{'eval_loss': 0.8283909559249878, 'eval_runtime': 5.8415, 'eval_samples_per_second': 17.119, 'eval_steps_per_second': 2.225, 'epoch': 0.35}
{'loss': 0.6641, 'learning_rate': 6.500000000000001e-05, 'epoch': 0.35}
[2023-03-12 18:41:20,047] [INFO] [logging.py:75:log_dist] [Rank 0] step=530, skipped=0, lr=[6.466666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:41:20,049] [INFO] [timer.py:198:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=2.994494954616335, CurrSamplesPerSec=3.070282710524948, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7481, 'learning_rate': 6.466666666666666e-05, 'epoch': 0.35}
{'loss': 0.6365, 'learning_rate': 6.433333333333333e-05, 'epoch': 0.36}
[2023-03-12 18:41:47,471] [INFO] [logging.py:75:log_dist] [Rank 0] step=540, skipped=0, lr=[6.400000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:41:47,483] [INFO] [timer.py:198:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=2.9934348822197796, CurrSamplesPerSec=3.0110379673592753, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7228, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.36}
{'eval_loss': 0.827414333820343, 'eval_runtime': 5.8268, 'eval_samples_per_second': 17.162, 'eval_steps_per_second': 2.231, 'epoch': 0.36}
{'loss': 0.9712, 'learning_rate': 6.366666666666668e-05, 'epoch': 0.36}
[2023-03-12 18:42:20,712] [INFO] [logging.py:75:log_dist] [Rank 0] step=550, skipped=0, lr=[6.333333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:42:20,713] [INFO] [timer.py:198:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=2.992466270035882, CurrSamplesPerSec=2.8843409141508305, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6031, 'learning_rate': 6.333333333333333e-05, 'epoch': 0.37}
{'loss': 0.4993, 'learning_rate': 6.3e-05, 'epoch': 0.37}
[2023-03-12 18:42:48,058] [INFO] [logging.py:75:log_dist] [Rank 0] step=560, skipped=0, lr=[6.266666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:42:48,072] [INFO] [timer.py:198:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=2.9916654355366368, CurrSamplesPerSec=2.8057656512613827, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6391, 'learning_rate': 6.266666666666667e-05, 'epoch': 0.37}
{'eval_loss': 0.8275779485702515, 'eval_runtime': 5.9456, 'eval_samples_per_second': 16.819, 'eval_steps_per_second': 2.187, 'epoch': 0.37}
{'loss': 0.7264, 'learning_rate': 6.233333333333334e-05, 'epoch': 0.38}
[2023-03-12 18:43:20,882] [INFO] [logging.py:75:log_dist] [Rank 0] step=570, skipped=0, lr=[6.2e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:43:20,883] [INFO] [timer.py:198:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=2.9918578478136966, CurrSamplesPerSec=3.1651944403699064, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7105, 'learning_rate': 6.2e-05, 'epoch': 0.38}
{'loss': 0.8505, 'learning_rate': 6.166666666666667e-05, 'epoch': 0.38}
[2023-03-12 18:43:47,557] [INFO] [logging.py:75:log_dist] [Rank 0] step=580, skipped=0, lr=[6.133333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:43:47,570] [INFO] [timer.py:198:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=2.992210437216389, CurrSamplesPerSec=2.8846684775922675, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0162, 'learning_rate': 6.133333333333334e-05, 'epoch': 0.39}
{'eval_loss': 0.8272438049316406, 'eval_runtime': 6.3129, 'eval_samples_per_second': 15.841, 'eval_steps_per_second': 2.059, 'epoch': 0.39}
{'loss': 0.6197, 'learning_rate': 6.1e-05, 'epoch': 0.39}
[2023-03-12 18:44:21,080] [INFO] [logging.py:75:log_dist] [Rank 0] step=590, skipped=0, lr=[6.066666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:44:21,087] [INFO] [timer.py:198:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=2.9917833683592514, CurrSamplesPerSec=2.7227079308132422, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6386, 'learning_rate': 6.066666666666667e-05, 'epoch': 0.39}
{'loss': 0.7444, 'learning_rate': 6.033333333333334e-05, 'epoch': 0.4}
[2023-03-12 18:44:47,470] [INFO] [logging.py:75:log_dist] [Rank 0] step=600, skipped=0, lr=[6e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:44:47,479] [INFO] [timer.py:198:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=2.992762827968925, CurrSamplesPerSec=2.700673759284805, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7632, 'learning_rate': 6e-05, 'epoch': 0.4}
{'eval_loss': 0.8265033960342407, 'eval_runtime': 6.7427, 'eval_samples_per_second': 14.831, 'eval_steps_per_second': 1.928, 'epoch': 0.4}
{'loss': 0.6893, 'learning_rate': 5.966666666666667e-05, 'epoch': 0.4}
[2023-03-12 18:45:24,987] [INFO] [logging.py:75:log_dist] [Rank 0] step=610, skipped=0, lr=[5.9333333333333343e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:45:24,989] [INFO] [timer.py:198:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=2.985671677943343, CurrSamplesPerSec=1.2541957492005604, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6629, 'learning_rate': 5.9333333333333343e-05, 'epoch': 0.41}
{'loss': 0.7255, 'learning_rate': 5.9e-05, 'epoch': 0.41}
[2023-03-12 18:45:51,603] [INFO] [logging.py:75:log_dist] [Rank 0] step=620, skipped=0, lr=[5.866666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:45:51,604] [INFO] [timer.py:198:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=2.9863207872112745, CurrSamplesPerSec=3.082712538965209, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5114, 'learning_rate': 5.866666666666667e-05, 'epoch': 0.41}
{'eval_loss': 0.826773464679718, 'eval_runtime': 6.6727, 'eval_samples_per_second': 14.986, 'eval_steps_per_second': 1.948, 'epoch': 0.41}
{'loss': 1.0712, 'learning_rate': 5.833333333333334e-05, 'epoch': 0.42}
[2023-03-12 18:46:24,521] [INFO] [logging.py:75:log_dist] [Rank 0] step=630, skipped=0, lr=[5.8e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:46:24,523] [INFO] [timer.py:198:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=2.9876626652157303, CurrSamplesPerSec=2.915407863384742, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6022, 'learning_rate': 5.8e-05, 'epoch': 0.42}
{'loss': 0.9132, 'learning_rate': 5.766666666666667e-05, 'epoch': 0.42}
[2023-03-12 18:46:51,349] [INFO] [logging.py:75:log_dist] [Rank 0] step=640, skipped=0, lr=[5.7333333333333336e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:46:51,363] [INFO] [timer.py:198:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=2.9879620859288236, CurrSamplesPerSec=3.2041811762843224, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6893, 'learning_rate': 5.7333333333333336e-05, 'epoch': 0.43}
{'eval_loss': 0.8273460268974304, 'eval_runtime': 6.1266, 'eval_samples_per_second': 16.322, 'eval_steps_per_second': 2.122, 'epoch': 0.43}
{'loss': 0.8427, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.43}
[2023-03-12 18:47:24,618] [INFO] [logging.py:75:log_dist] [Rank 0] step=650, skipped=0, lr=[5.666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:47:24,620] [INFO] [timer.py:198:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=2.9876659356601993, CurrSamplesPerSec=3.0964707940784844, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8281, 'learning_rate': 5.666666666666667e-05, 'epoch': 0.43}
{'loss': 0.8628, 'learning_rate': 5.633333333333334e-05, 'epoch': 0.44}
[2023-03-12 18:47:51,492] [INFO] [logging.py:75:log_dist] [Rank 0] step=660, skipped=0, lr=[5.6000000000000006e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:47:51,502] [INFO] [timer.py:198:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=2.9878192281377864, CurrSamplesPerSec=3.2248081564664384, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5666, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.44}
{'eval_loss': 0.8262930512428284, 'eval_runtime': 5.7725, 'eval_samples_per_second': 17.324, 'eval_steps_per_second': 2.252, 'epoch': 0.44}
{'loss': 0.7092, 'learning_rate': 5.566666666666667e-05, 'epoch': 0.44}
[2023-03-12 18:48:24,210] [INFO] [logging.py:75:log_dist] [Rank 0] step=670, skipped=0, lr=[5.5333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:48:24,218] [INFO] [timer.py:198:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=2.987844888441263, CurrSamplesPerSec=3.0614544814549176, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9014, 'learning_rate': 5.5333333333333334e-05, 'epoch': 0.45}
{'loss': 0.8205, 'learning_rate': 5.500000000000001e-05, 'epoch': 0.45}
[2023-03-12 18:48:51,840] [INFO] [logging.py:75:log_dist] [Rank 0] step=680, skipped=0, lr=[5.466666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:48:51,842] [INFO] [timer.py:198:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=2.986711762129486, CurrSamplesPerSec=2.912545257839484, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6155, 'learning_rate': 5.466666666666666e-05, 'epoch': 0.45}
{'eval_loss': 0.8254510760307312, 'eval_runtime': 5.9273, 'eval_samples_per_second': 16.871, 'eval_steps_per_second': 2.193, 'epoch': 0.45}
{'loss': 0.8375, 'learning_rate': 5.433333333333334e-05, 'epoch': 0.46}
[2023-03-12 18:49:24,827] [INFO] [logging.py:75:log_dist] [Rank 0] step=690, skipped=0, lr=[5.4000000000000005e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:49:24,835] [INFO] [timer.py:198:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=2.986644372314959, CurrSamplesPerSec=3.047488955560492, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8152, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.46}
{'loss': 0.6101, 'learning_rate': 5.3666666666666666e-05, 'epoch': 0.46}
[2023-03-12 18:49:51,551] [INFO] [logging.py:75:log_dist] [Rank 0] step=700, skipped=0, lr=[5.333333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:49:51,552] [INFO] [timer.py:198:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=2.9869924974191093, CurrSamplesPerSec=2.79335995735007, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5822, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.47}
{'eval_loss': 0.8254426717758179, 'eval_runtime': 6.1691, 'eval_samples_per_second': 16.21, 'eval_steps_per_second': 2.107, 'epoch': 0.47}
{'loss': 0.5751, 'learning_rate': 5.300000000000001e-05, 'epoch': 0.47}
[2023-03-12 18:50:24,276] [INFO] [logging.py:75:log_dist] [Rank 0] step=710, skipped=0, lr=[5.266666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:50:24,295] [INFO] [timer.py:198:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=2.9876399654603993, CurrSamplesPerSec=3.0174371340885253, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8218, 'learning_rate': 5.266666666666666e-05, 'epoch': 0.47}
{'loss': 0.8254, 'learning_rate': 5.2333333333333336e-05, 'epoch': 0.48}
[2023-03-12 18:50:51,140] [INFO] [logging.py:75:log_dist] [Rank 0] step=720, skipped=0, lr=[5.2000000000000004e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:50:51,154] [INFO] [timer.py:198:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=2.9877681175605586, CurrSamplesPerSec=3.094570304423074, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0477, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.48}
{'eval_loss': 0.8237578868865967, 'eval_runtime': 6.4282, 'eval_samples_per_second': 15.556, 'eval_steps_per_second': 2.022, 'epoch': 0.48}
{'loss': 0.9292, 'learning_rate': 5.166666666666667e-05, 'epoch': 0.48}
[2023-03-12 18:51:24,169] [INFO] [logging.py:75:log_dist] [Rank 0] step=730, skipped=0, lr=[5.133333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:51:24,184] [INFO] [timer.py:198:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=2.9883382178774998, CurrSamplesPerSec=3.113292550721873, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6102, 'learning_rate': 5.133333333333333e-05, 'epoch': 0.49}
{'loss': 0.755, 'learning_rate': 5.1000000000000006e-05, 'epoch': 0.49}
[2023-03-12 18:51:51,325] [INFO] [logging.py:75:log_dist] [Rank 0] step=740, skipped=0, lr=[5.0666666666666674e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:51:51,326] [INFO] [timer.py:198:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=2.9880998417933617, CurrSamplesPerSec=3.07828969512811, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0177, 'learning_rate': 5.0666666666666674e-05, 'epoch': 0.49}
{'eval_loss': 0.8237178325653076, 'eval_runtime': 5.9033, 'eval_samples_per_second': 16.94, 'eval_steps_per_second': 2.202, 'epoch': 0.49}
{'loss': 0.7837, 'learning_rate': 5.0333333333333335e-05, 'epoch': 0.5}
[2023-03-12 18:52:24,805] [INFO] [logging.py:75:log_dist] [Rank 0] step=750, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:52:24,812] [INFO] [timer.py:198:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=2.9871760290372413, CurrSamplesPerSec=3.0541564673893307, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7185, 'learning_rate': 5e-05, 'epoch': 0.5}
{'loss': 0.787, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.5}
[2023-03-12 18:52:51,780] [INFO] [logging.py:75:log_dist] [Rank 0] step=760, skipped=0, lr=[4.933333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:52:51,786] [INFO] [timer.py:198:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=2.987069384183941, CurrSamplesPerSec=3.151767179887562, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5074, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.51}
{'eval_loss': 0.8249720931053162, 'eval_runtime': 5.9917, 'eval_samples_per_second': 16.69, 'eval_steps_per_second': 2.17, 'epoch': 0.51}
{'loss': 0.6681, 'learning_rate': 4.9e-05, 'epoch': 0.51}
[2023-03-12 18:53:24,470] [INFO] [logging.py:75:log_dist] [Rank 0] step=770, skipped=0, lr=[4.866666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:53:24,471] [INFO] [timer.py:198:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=2.9874996577869597, CurrSamplesPerSec=3.099431978255299, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.86, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.51}
{'loss': 0.9617, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.52}
[2023-03-12 18:53:51,054] [INFO] [logging.py:75:log_dist] [Rank 0] step=780, skipped=0, lr=[4.8e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:53:51,055] [INFO] [timer.py:198:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=2.988009374758355, CurrSamplesPerSec=2.7817182596884686, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7329, 'learning_rate': 4.8e-05, 'epoch': 0.52}
{'eval_loss': 0.824596107006073, 'eval_runtime': 5.9828, 'eval_samples_per_second': 16.715, 'eval_steps_per_second': 2.173, 'epoch': 0.52}
{'loss': 1.3006, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.52}
[2023-03-12 18:54:24,101] [INFO] [logging.py:75:log_dist] [Rank 0] step=790, skipped=0, lr=[4.7333333333333336e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:54:24,102] [INFO] [timer.py:198:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=2.9878780896048514, CurrSamplesPerSec=2.778148636241664, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8404, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.53}
{'loss': 0.7584, 'learning_rate': 4.7e-05, 'epoch': 0.53}
[2023-03-12 18:54:51,720] [INFO] [logging.py:75:log_dist] [Rank 0] step=800, skipped=0, lr=[4.666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:54:51,722] [INFO] [timer.py:198:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=2.9869268883713347, CurrSamplesPerSec=2.5665815255474222, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.507, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.53}
{'eval_loss': 0.8235822916030884, 'eval_runtime': 6.4393, 'eval_samples_per_second': 15.53, 'eval_steps_per_second': 2.019, 'epoch': 0.53}
{'loss': 0.7493, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.54}
[2023-03-12 18:55:25,695] [INFO] [logging.py:75:log_dist] [Rank 0] step=810, skipped=0, lr=[4.600000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:55:25,696] [INFO] [timer.py:198:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=2.986223618366645, CurrSamplesPerSec=2.77848910400635, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6658, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.54}
{'loss': 0.8047, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.54}
[2023-03-12 18:55:52,649] [INFO] [logging.py:75:log_dist] [Rank 0] step=820, skipped=0, lr=[4.5333333333333335e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:55:52,650] [INFO] [timer.py:198:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=2.986262111598813, CurrSamplesPerSec=2.505240674418771, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9181, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.55}
{'eval_loss': 0.8234174847602844, 'eval_runtime': 6.384, 'eval_samples_per_second': 15.664, 'eval_steps_per_second': 2.036, 'epoch': 0.55}
{'loss': 0.9674, 'learning_rate': 4.5e-05, 'epoch': 0.55}
[2023-03-12 18:56:25,504] [INFO] [logging.py:75:log_dist] [Rank 0] step=830, skipped=0, lr=[4.466666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:56:25,505] [INFO] [timer.py:198:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=2.9869338899595186, CurrSamplesPerSec=3.0224226936218552, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8033, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.55}
{'loss': 0.8081, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.56}
[2023-03-12 18:56:52,271] [INFO] [logging.py:75:log_dist] [Rank 0] step=840, skipped=0, lr=[4.4000000000000006e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:56:52,273] [INFO] [timer.py:198:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=2.9872531227821377, CurrSamplesPerSec=3.064446711196192, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7747, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.56}
{'eval_loss': 0.822732150554657, 'eval_runtime': 6.0346, 'eval_samples_per_second': 16.571, 'eval_steps_per_second': 2.154, 'epoch': 0.56}
{'loss': 0.9605, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.56}
[2023-03-12 18:57:25,301] [INFO] [logging.py:75:log_dist] [Rank 0] step=850, skipped=0, lr=[4.3333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:57:25,305] [INFO] [timer.py:198:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=2.9872154390184575, CurrSamplesPerSec=3.1309920836020297, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6802, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.57}
{'loss': 0.9096, 'learning_rate': 4.3e-05, 'epoch': 0.57}
[2023-03-12 18:57:52,236] [INFO] [logging.py:75:log_dist] [Rank 0] step=860, skipped=0, lr=[4.266666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:57:52,237] [INFO] [timer.py:198:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=2.9872382426129627, CurrSamplesPerSec=3.0970592622237842, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6318, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.57}
{'eval_loss': 0.8223460912704468, 'eval_runtime': 6.3886, 'eval_samples_per_second': 15.653, 'eval_steps_per_second': 2.035, 'epoch': 0.57}
{'loss': 0.7179, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.58}
[2023-03-12 18:58:25,661] [INFO] [logging.py:75:log_dist] [Rank 0] step=870, skipped=0, lr=[4.2e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:58:25,662] [INFO] [timer.py:198:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=2.987208384624903, CurrSamplesPerSec=3.153926237012334, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7754, 'learning_rate': 4.2e-05, 'epoch': 0.58}
{'loss': 0.6879, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.58}
[2023-03-12 18:58:52,636] [INFO] [logging.py:75:log_dist] [Rank 0] step=880, skipped=0, lr=[4.133333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:58:52,638] [INFO] [timer.py:198:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=2.987187987716666, CurrSamplesPerSec=3.186211102141943, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8074, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.59}
{'eval_loss': 0.8225896954536438, 'eval_runtime': 5.8627, 'eval_samples_per_second': 17.057, 'eval_steps_per_second': 2.217, 'epoch': 0.59}
{'loss': 0.6026, 'learning_rate': 4.1e-05, 'epoch': 0.59}
[2023-03-12 18:59:25,277] [INFO] [logging.py:75:log_dist] [Rank 0] step=890, skipped=0, lr=[4.066666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:59:25,279] [INFO] [timer.py:198:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=2.9873753379172494, CurrSamplesPerSec=3.1328243858584592, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8587, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.59}
{'loss': 0.6368, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.6}
[2023-03-12 18:59:52,368] [INFO] [logging.py:75:log_dist] [Rank 0] step=900, skipped=0, lr=[4e-05], mom=[[0.9, 0.999]]
[2023-03-12 18:59:52,384] [INFO] [timer.py:198:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=2.987149921207282, CurrSamplesPerSec=2.655714485163363, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5343, 'learning_rate': 4e-05, 'epoch': 0.6}
{'eval_loss': 0.8222280740737915, 'eval_runtime': 5.8831, 'eval_samples_per_second': 16.998, 'eval_steps_per_second': 2.21, 'epoch': 0.6}
{'loss': 0.6399, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.6}
[2023-03-12 19:00:25,265] [INFO] [logging.py:75:log_dist] [Rank 0] step=910, skipped=0, lr=[3.933333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:00:25,266] [INFO] [timer.py:198:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=2.987077502745559, CurrSamplesPerSec=2.8513482163964774, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6677, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.61}
{'loss': 0.7196, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.61}
[2023-03-12 19:00:52,000] [INFO] [logging.py:75:log_dist] [Rank 0] step=920, skipped=0, lr=[3.866666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:00:52,005] [INFO] [timer.py:198:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=2.987398559860651, CurrSamplesPerSec=3.084442820053014, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7858, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.61}
{'eval_loss': 0.8220975995063782, 'eval_runtime': 6.1857, 'eval_samples_per_second': 16.166, 'eval_steps_per_second': 2.102, 'epoch': 0.61}
{'loss': 0.6384, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.62}
[2023-03-12 19:01:24,917] [INFO] [logging.py:75:log_dist] [Rank 0] step=930, skipped=0, lr=[3.8e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:01:24,920] [INFO] [timer.py:198:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=2.987701079030895, CurrSamplesPerSec=3.061817364224739, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9567, 'learning_rate': 3.8e-05, 'epoch': 0.62}
{'loss': 0.6662, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.62}
[2023-03-12 19:01:52,414] [INFO] [logging.py:75:log_dist] [Rank 0] step=940, skipped=0, lr=[3.733333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:01:52,415] [INFO] [timer.py:198:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=2.9870560044986876, CurrSamplesPerSec=2.6414071810493085, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.78, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.63}
{'eval_loss': 0.8213459253311157, 'eval_runtime': 6.3476, 'eval_samples_per_second': 15.754, 'eval_steps_per_second': 2.048, 'epoch': 0.63}
{'loss': 0.8502, 'learning_rate': 3.7e-05, 'epoch': 0.63}
[2023-03-12 19:02:25,785] [INFO] [logging.py:75:log_dist] [Rank 0] step=950, skipped=0, lr=[3.6666666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:02:25,795] [INFO] [timer.py:198:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=2.9869946301774637, CurrSamplesPerSec=3.0022495555378597, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6262, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.63}
{'loss': 0.7034, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.64}
[2023-03-12 19:02:52,707] [INFO] [logging.py:75:log_dist] [Rank 0] step=960, skipped=0, lr=[3.6e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:02:52,722] [INFO] [timer.py:198:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=2.9870107186659807, CurrSamplesPerSec=3.00187245579063, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5908, 'learning_rate': 3.6e-05, 'epoch': 0.64}
{'eval_loss': 0.8206102252006531, 'eval_runtime': 5.713, 'eval_samples_per_second': 17.504, 'eval_steps_per_second': 2.276, 'epoch': 0.64}
{'loss': 0.8626, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.64}
[2023-03-12 19:03:25,728] [INFO] [logging.py:75:log_dist] [Rank 0] step=970, skipped=0, lr=[3.5333333333333336e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:03:25,729] [INFO] [timer.py:198:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=2.9866078139511685, CurrSamplesPerSec=3.111293756351579, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7381, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.65}
{'loss': 0.5657, 'learning_rate': 3.5e-05, 'epoch': 0.65}
[2023-03-12 19:03:52,482] [INFO] [logging.py:75:log_dist] [Rank 0] step=980, skipped=0, lr=[3.466666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:03:52,488] [INFO] [timer.py:198:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=2.986800647615631, CurrSamplesPerSec=2.9472981150060376, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7839, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.65}
{'eval_loss': 0.8202327489852905, 'eval_runtime': 5.8847, 'eval_samples_per_second': 16.993, 'eval_steps_per_second': 2.209, 'epoch': 0.65}
{'loss': 0.7145, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.66}
[2023-03-12 19:04:25,109] [INFO] [logging.py:75:log_dist] [Rank 0] step=990, skipped=0, lr=[3.4000000000000007e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:04:25,123] [INFO] [timer.py:198:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=2.987102391433428, CurrSamplesPerSec=2.699953378647936, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.0242, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.66}
{'loss': 0.8543, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.66}
[2023-03-12 19:04:52,761] [INFO] [logging.py:75:log_dist] [Rank 0] step=1000, skipped=0, lr=[3.3333333333333335e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:04:52,773] [INFO] [timer.py:198:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=2.986343994479677, CurrSamplesPerSec=2.3504187255506435, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8573, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.67}
{'eval_loss': 0.819389820098877, 'eval_runtime': 6.8444, 'eval_samples_per_second': 14.61, 'eval_steps_per_second': 1.899, 'epoch': 0.67}
{'loss': 0.9777, 'learning_rate': 3.3e-05, 'epoch': 0.67}
[2023-03-12 19:05:26,628] [INFO] [logging.py:75:log_dist] [Rank 0] step=1010, skipped=0, lr=[3.266666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:05:26,635] [INFO] [timer.py:198:stop] epoch=0/micro_step=1010/global_step=1010, RunningAvgSamplesPerSec=2.986301356868311, CurrSamplesPerSec=2.8644170887246765, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9624, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.67}
{'loss': 0.6538, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.68}
[2023-03-12 19:05:54,029] [INFO] [logging.py:75:log_dist] [Rank 0] step=1020, skipped=0, lr=[3.2000000000000005e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:05:54,030] [INFO] [timer.py:198:stop] epoch=0/micro_step=1020/global_step=1020, RunningAvgSamplesPerSec=2.9858185251770544, CurrSamplesPerSec=3.05138795260179, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6226, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.68}
{'eval_loss': 0.8188409209251404, 'eval_runtime': 6.5108, 'eval_samples_per_second': 15.359, 'eval_steps_per_second': 1.997, 'epoch': 0.68}
{'loss': 0.7026, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.68}
[2023-03-12 19:06:27,403] [INFO] [logging.py:75:log_dist] [Rank 0] step=1030, skipped=0, lr=[3.1333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:06:27,416] [INFO] [timer.py:198:stop] epoch=0/micro_step=1030/global_step=1030, RunningAvgSamplesPerSec=2.9859569433463458, CurrSamplesPerSec=3.124951758235372, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6281, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.69}
{'loss': 0.6661, 'learning_rate': 3.1e-05, 'epoch': 0.69}
[2023-03-12 19:06:54,708] [INFO] [logging.py:75:log_dist] [Rank 0] step=1040, skipped=0, lr=[3.066666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:06:54,709] [INFO] [timer.py:198:stop] epoch=0/micro_step=1040/global_step=1040, RunningAvgSamplesPerSec=2.9856081918281583, CurrSamplesPerSec=2.8330914054937995, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7314, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.69}
{'eval_loss': 0.8190637826919556, 'eval_runtime': 5.7849, 'eval_samples_per_second': 17.287, 'eval_steps_per_second': 2.247, 'epoch': 0.69}
{'loss': 0.7356, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.7}
[2023-03-12 19:07:27,535] [INFO] [logging.py:75:log_dist] [Rank 0] step=1050, skipped=0, lr=[3e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:07:27,537] [INFO] [timer.py:198:stop] epoch=0/micro_step=1050/global_step=1050, RunningAvgSamplesPerSec=2.985603030760749, CurrSamplesPerSec=2.830577434917761, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7316, 'learning_rate': 3e-05, 'epoch': 0.7}
{'loss': 0.8738, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.7}
[2023-03-12 19:07:54,411] [INFO] [logging.py:75:log_dist] [Rank 0] step=1060, skipped=0, lr=[2.9333333333333336e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:07:54,426] [INFO] [timer.py:198:stop] epoch=0/micro_step=1060/global_step=1060, RunningAvgSamplesPerSec=2.9857929463305637, CurrSamplesPerSec=3.0927283016850606, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5896, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.71}
{'eval_loss': 0.8191455602645874, 'eval_runtime': 6.3392, 'eval_samples_per_second': 15.775, 'eval_steps_per_second': 2.051, 'epoch': 0.71}
{'loss': 0.7609, 'learning_rate': 2.9e-05, 'epoch': 0.71}
[2023-03-12 19:08:27,997] [INFO] [logging.py:75:log_dist] [Rank 0] step=1070, skipped=0, lr=[2.8666666666666668e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:08:28,000] [INFO] [timer.py:198:stop] epoch=0/micro_step=1070/global_step=1070, RunningAvgSamplesPerSec=2.985567860250396, CurrSamplesPerSec=2.8952991039995584, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7677, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.71}
{'loss': 0.9223, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.72}
[2023-03-12 19:08:54,630] [INFO] [logging.py:75:log_dist] [Rank 0] step=1080, skipped=0, lr=[2.8000000000000003e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:08:54,644] [INFO] [timer.py:198:stop] epoch=0/micro_step=1080/global_step=1080, RunningAvgSamplesPerSec=2.9858707557277517, CurrSamplesPerSec=2.953883945564865, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7303, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.72}
{'eval_loss': 0.8188215494155884, 'eval_runtime': 6.1965, 'eval_samples_per_second': 16.138, 'eval_steps_per_second': 2.098, 'epoch': 0.72}
{'loss': 0.7626, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.72}
[2023-03-12 19:09:28,020] [INFO] [logging.py:75:log_dist] [Rank 0] step=1090, skipped=0, lr=[2.733333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:09:28,022] [INFO] [timer.py:198:stop] epoch=0/micro_step=1090/global_step=1090, RunningAvgSamplesPerSec=2.9856845247839146, CurrSamplesPerSec=3.1142692095794335, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9784, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.73}
{'loss': 0.6847, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.73}
[2023-03-12 19:09:55,148] [INFO] [logging.py:75:log_dist] [Rank 0] step=1100, skipped=0, lr=[2.6666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:09:55,149] [INFO] [timer.py:198:stop] epoch=0/micro_step=1100/global_step=1100, RunningAvgSamplesPerSec=2.985517967827739, CurrSamplesPerSec=2.730683333435059, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8427, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.73}
{'eval_loss': 0.8182925581932068, 'eval_runtime': 5.9876, 'eval_samples_per_second': 16.701, 'eval_steps_per_second': 2.171, 'epoch': 0.73}
{'loss': 0.7624, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.74}
[2023-03-12 19:10:28,375] [INFO] [logging.py:75:log_dist] [Rank 0] step=1110, skipped=0, lr=[2.6000000000000002e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:10:28,376] [INFO] [timer.py:198:stop] epoch=0/micro_step=1110/global_step=1110, RunningAvgSamplesPerSec=2.985287353986707, CurrSamplesPerSec=3.0871733893753803, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.708, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.74}
{'loss': 0.7139, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.74}
[2023-03-12 19:10:55,439] [INFO] [logging.py:75:log_dist] [Rank 0] step=1120, skipped=0, lr=[2.5333333333333337e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:10:55,441] [INFO] [timer.py:198:stop] epoch=0/micro_step=1120/global_step=1120, RunningAvgSamplesPerSec=2.9852030810723025, CurrSamplesPerSec=2.8634630269505457, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6088, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.75}
{'eval_loss': 0.8182447552680969, 'eval_runtime': 5.7972, 'eval_samples_per_second': 17.25, 'eval_steps_per_second': 2.242, 'epoch': 0.75}
{'loss': 0.9056, 'learning_rate': 2.5e-05, 'epoch': 0.75}
[2023-03-12 19:11:28,624] [INFO] [logging.py:75:log_dist] [Rank 0] step=1130, skipped=0, lr=[2.466666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:11:28,638] [INFO] [timer.py:198:stop] epoch=0/micro_step=1130/global_step=1130, RunningAvgSamplesPerSec=2.9848142074262536, CurrSamplesPerSec=3.054833250440389, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5464, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.75}
{'loss': 0.6346, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.76}
[2023-03-12 19:11:55,538] [INFO] [logging.py:75:log_dist] [Rank 0] step=1140, skipped=0, lr=[2.4e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:11:55,539] [INFO] [timer.py:198:stop] epoch=0/micro_step=1140/global_step=1140, RunningAvgSamplesPerSec=2.9848619699716807, CurrSamplesPerSec=3.0776120774678017, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7256, 'learning_rate': 2.4e-05, 'epoch': 0.76}
{'eval_loss': 0.8182772994041443, 'eval_runtime': 6.2146, 'eval_samples_per_second': 16.091, 'eval_steps_per_second': 2.092, 'epoch': 0.76}
{'loss': 0.8694, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.76}
[2023-03-12 19:12:29,055] [INFO] [logging.py:75:log_dist] [Rank 0] step=1150, skipped=0, lr=[2.3333333333333336e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:12:29,057] [INFO] [timer.py:198:stop] epoch=0/micro_step=1150/global_step=1150, RunningAvgSamplesPerSec=2.9845959787268157, CurrSamplesPerSec=2.865367382096953, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6963, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.77}
{'loss': 0.7157, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.77}
[2023-03-12 19:12:55,877] [INFO] [logging.py:75:log_dist] [Rank 0] step=1160, skipped=0, lr=[2.2666666666666668e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:12:55,878] [INFO] [timer.py:198:stop] epoch=0/micro_step=1160/global_step=1160, RunningAvgSamplesPerSec=2.984739107061025, CurrSamplesPerSec=3.049114519610259, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9815, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.77}
{'eval_loss': 0.8180713653564453, 'eval_runtime': 6.2946, 'eval_samples_per_second': 15.887, 'eval_steps_per_second': 2.065, 'epoch': 0.77}
{'loss': 0.7229, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.78}
[2023-03-12 19:13:28,943] [INFO] [logging.py:75:log_dist] [Rank 0] step=1170, skipped=0, lr=[2.2000000000000003e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:13:28,957] [INFO] [timer.py:198:stop] epoch=0/micro_step=1170/global_step=1170, RunningAvgSamplesPerSec=2.9849436853447786, CurrSamplesPerSec=3.17499640671943, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7053, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.78}
{'loss': 0.8583, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.78}
[2023-03-12 19:13:55,455] [INFO] [logging.py:75:log_dist] [Rank 0] step=1180, skipped=0, lr=[2.1333333333333335e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:13:55,470] [INFO] [timer.py:198:stop] epoch=0/micro_step=1180/global_step=1180, RunningAvgSamplesPerSec=2.9854042245375596, CurrSamplesPerSec=2.7753284959392093, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6235, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.79}
{'eval_loss': 0.8178200721740723, 'eval_runtime': 5.9155, 'eval_samples_per_second': 16.905, 'eval_steps_per_second': 2.198, 'epoch': 0.79}
{'loss': 0.9643, 'learning_rate': 2.1e-05, 'epoch': 0.79}
[2023-03-12 19:14:28,763] [INFO] [logging.py:75:log_dist] [Rank 0] step=1190, skipped=0, lr=[2.0666666666666666e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:14:28,771] [INFO] [timer.py:198:stop] epoch=0/micro_step=1190/global_step=1190, RunningAvgSamplesPerSec=2.985071257618365, CurrSamplesPerSec=3.01298546433267, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5727, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.79}
{'loss': 0.9154, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.8}
[2023-03-12 19:14:55,588] [INFO] [logging.py:75:log_dist] [Rank 0] step=1200, skipped=0, lr=[2e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:14:55,590] [INFO] [timer.py:198:stop] epoch=0/micro_step=1200/global_step=1200, RunningAvgSamplesPerSec=2.9852721911141202, CurrSamplesPerSec=2.8026344792436575, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.4954, 'learning_rate': 2e-05, 'epoch': 0.8}
{'eval_loss': 0.817849338054657, 'eval_runtime': 6.39, 'eval_samples_per_second': 15.649, 'eval_steps_per_second': 2.034, 'epoch': 0.8}
{'loss': 0.8415, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.8}
[2023-03-12 19:15:29,175] [INFO] [logging.py:75:log_dist] [Rank 0] step=1210, skipped=0, lr=[1.9333333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:15:29,177] [INFO] [timer.py:198:stop] epoch=0/micro_step=1210/global_step=1210, RunningAvgSamplesPerSec=2.985121941413474, CurrSamplesPerSec=2.7206175626681004, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6816, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.81}
{'loss': 0.9451, 'learning_rate': 1.9e-05, 'epoch': 0.81}
[2023-03-12 19:15:58,833] [INFO] [logging.py:75:log_dist] [Rank 0] step=1220, skipped=0, lr=[1.866666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:15:58,844] [INFO] [timer.py:198:stop] epoch=0/micro_step=1220/global_step=1220, RunningAvgSamplesPerSec=2.9826423072698565, CurrSamplesPerSec=1.3737939948034457, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7839, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.81}
{'eval_loss': 0.8180043697357178, 'eval_runtime': 6.3495, 'eval_samples_per_second': 15.749, 'eval_steps_per_second': 2.047, 'epoch': 0.81}
{'loss': 0.6772, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.82}
[2023-03-12 19:16:32,312] [INFO] [logging.py:75:log_dist] [Rank 0] step=1230, skipped=0, lr=[1.8e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:16:32,321] [INFO] [timer.py:198:stop] epoch=0/micro_step=1230/global_step=1230, RunningAvgSamplesPerSec=2.98254405267339, CurrSamplesPerSec=2.8443154475941586, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 1.079, 'learning_rate': 1.8e-05, 'epoch': 0.82}
{'loss': 0.9259, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.82}
[2023-03-12 19:16:59,327] [INFO] [logging.py:75:log_dist] [Rank 0] step=1240, skipped=0, lr=[1.7333333333333336e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:16:59,329] [INFO] [timer.py:198:stop] epoch=0/micro_step=1240/global_step=1240, RunningAvgSamplesPerSec=2.982515515336154, CurrSamplesPerSec=3.010328323779906, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7253, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.83}
{'eval_loss': 0.8180570006370544, 'eval_runtime': 6.3521, 'eval_samples_per_second': 15.743, 'eval_steps_per_second': 2.047, 'epoch': 0.83}
{'loss': 0.7016, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.83}
[2023-03-12 19:17:32,248] [INFO] [logging.py:75:log_dist] [Rank 0] step=1250, skipped=0, lr=[1.6666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:17:32,256] [INFO] [timer.py:198:stop] epoch=0/micro_step=1250/global_step=1250, RunningAvgSamplesPerSec=2.9829072659730915, CurrSamplesPerSec=3.1077323783589987, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5785, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.83}
{'loss': 0.998, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.84}
[2023-03-12 19:17:59,479] [INFO] [logging.py:75:log_dist] [Rank 0] step=1260, skipped=0, lr=[1.6000000000000003e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:17:59,491] [INFO] [timer.py:198:stop] epoch=0/micro_step=1260/global_step=1260, RunningAvgSamplesPerSec=2.9826737498617875, CurrSamplesPerSec=3.169184521159328, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5772, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.84}
{'eval_loss': 0.8179119825363159, 'eval_runtime': 5.9068, 'eval_samples_per_second': 16.93, 'eval_steps_per_second': 2.201, 'epoch': 0.84}
{'loss': 0.6091, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.84}
[2023-03-12 19:18:32,527] [INFO] [logging.py:75:log_dist] [Rank 0] step=1270, skipped=0, lr=[1.5333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:18:32,539] [INFO] [timer.py:198:stop] epoch=0/micro_step=1270/global_step=1270, RunningAvgSamplesPerSec=2.9825353250399296, CurrSamplesPerSec=3.103345417671768, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9375, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.85}
{'loss': 0.6601, 'learning_rate': 1.5e-05, 'epoch': 0.85}
[2023-03-12 19:18:59,693] [INFO] [logging.py:75:log_dist] [Rank 0] step=1280, skipped=0, lr=[1.4666666666666668e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:18:59,705] [INFO] [timer.py:198:stop] epoch=0/micro_step=1280/global_step=1280, RunningAvgSamplesPerSec=2.982400460664298, CurrSamplesPerSec=2.8154656131475533, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.9134, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.85}
{'eval_loss': 0.8179500102996826, 'eval_runtime': 5.7616, 'eval_samples_per_second': 17.356, 'eval_steps_per_second': 2.256, 'epoch': 0.85}
{'loss': 0.7112, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.86}
[2023-03-12 19:19:32,088] [INFO] [logging.py:75:log_dist] [Rank 0] step=1290, skipped=0, lr=[1.4000000000000001e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:19:32,099] [INFO] [timer.py:198:stop] epoch=0/micro_step=1290/global_step=1290, RunningAvgSamplesPerSec=2.9827326570903714, CurrSamplesPerSec=2.8323773177055154, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.528, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.86}
{'loss': 0.6243, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.86}
[2023-03-12 19:19:59,284] [INFO] [logging.py:75:log_dist] [Rank 0] step=1300, skipped=0, lr=[1.3333333333333333e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:19:59,285] [INFO] [timer.py:198:stop] epoch=0/micro_step=1300/global_step=1300, RunningAvgSamplesPerSec=2.982596590783587, CurrSamplesPerSec=2.626495593627797, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8053, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.87}
{'eval_loss': 0.8180509805679321, 'eval_runtime': 6.1969, 'eval_samples_per_second': 16.137, 'eval_steps_per_second': 2.098, 'epoch': 0.87}
{'loss': 0.4859, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.87}
[2023-03-12 19:20:33,168] [INFO] [logging.py:75:log_dist] [Rank 0] step=1310, skipped=0, lr=[1.2666666666666668e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:20:33,174] [INFO] [timer.py:198:stop] epoch=0/micro_step=1310/global_step=1310, RunningAvgSamplesPerSec=2.982038319952565, CurrSamplesPerSec=2.8761384639609164, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7036, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.87}
{'loss': 0.7129, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.88}
[2023-03-12 19:20:59,847] [INFO] [logging.py:75:log_dist] [Rank 0] step=1320, skipped=0, lr=[1.2e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:20:59,849] [INFO] [timer.py:198:stop] epoch=0/micro_step=1320/global_step=1320, RunningAvgSamplesPerSec=2.9823633874073776, CurrSamplesPerSec=3.0230315569114805, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.697, 'learning_rate': 1.2e-05, 'epoch': 0.88}
{'eval_loss': 0.8178583383560181, 'eval_runtime': 6.1506, 'eval_samples_per_second': 16.259, 'eval_steps_per_second': 2.114, 'epoch': 0.88}
{'loss': 0.9984, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.88}
[2023-03-12 19:21:33,188] [INFO] [logging.py:75:log_dist] [Rank 0] step=1330, skipped=0, lr=[1.1333333333333334e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:21:33,192] [INFO] [timer.py:198:stop] epoch=0/micro_step=1330/global_step=1330, RunningAvgSamplesPerSec=2.9822206253360064, CurrSamplesPerSec=2.9856424249396967, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6833, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.89}
{'loss': 0.8516, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.89}
[2023-03-12 19:22:00,070] [INFO] [logging.py:75:log_dist] [Rank 0] step=1340, skipped=0, lr=[1.0666666666666667e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:22:00,072] [INFO] [timer.py:198:stop] epoch=0/micro_step=1340/global_step=1340, RunningAvgSamplesPerSec=2.9823491930832713, CurrSamplesPerSec=3.0824168909200043, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.575, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.89}
{'eval_loss': 0.8175955414772034, 'eval_runtime': 5.8937, 'eval_samples_per_second': 16.967, 'eval_steps_per_second': 2.206, 'epoch': 0.89}
{'loss': 0.7041, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.9}
[2023-03-12 19:22:33,205] [INFO] [logging.py:75:log_dist] [Rank 0] step=1350, skipped=0, lr=[1e-05], mom=[[0.9, 0.999]]
[2023-03-12 19:22:33,219] [INFO] [timer.py:198:stop] epoch=0/micro_step=1350/global_step=1350, RunningAvgSamplesPerSec=2.9822049760562694, CurrSamplesPerSec=3.1508997095451385, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.818, 'learning_rate': 1e-05, 'epoch': 0.9}
{'loss': 0.842, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.9}
[2023-03-12 19:23:00,065] [INFO] [logging.py:75:log_dist] [Rank 0] step=1360, skipped=0, lr=[9.333333333333334e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:23:00,079] [INFO] [timer.py:198:stop] epoch=0/micro_step=1360/global_step=1360, RunningAvgSamplesPerSec=2.982306991553636, CurrSamplesPerSec=2.8439984302863204, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6144, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.91}
{'eval_loss': 0.8174062967300415, 'eval_runtime': 5.8328, 'eval_samples_per_second': 17.145, 'eval_steps_per_second': 2.229, 'epoch': 0.91}
{'loss': 0.9648, 'learning_rate': 9e-06, 'epoch': 0.91}
[2023-03-12 19:23:32,544] [INFO] [logging.py:75:log_dist] [Rank 0] step=1370, skipped=0, lr=[8.666666666666668e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:23:32,564] [INFO] [timer.py:198:stop] epoch=0/micro_step=1370/global_step=1370, RunningAvgSamplesPerSec=2.982622782378285, CurrSamplesPerSec=2.919376513981836, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6352, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.91}
{'loss': 1.0032, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.92}
[2023-03-12 19:23:59,859] [INFO] [logging.py:75:log_dist] [Rank 0] step=1380, skipped=0, lr=[8.000000000000001e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:23:59,874] [INFO] [timer.py:198:stop] epoch=0/micro_step=1380/global_step=1380, RunningAvgSamplesPerSec=2.9823936303242227, CurrSamplesPerSec=3.065069265526453, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6921, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.92}
{'eval_loss': 0.8173990845680237, 'eval_runtime': 6.1729, 'eval_samples_per_second': 16.2, 'eval_steps_per_second': 2.106, 'epoch': 0.92}
{'loss': 0.9282, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.92}
[2023-03-12 19:24:33,112] [INFO] [logging.py:75:log_dist] [Rank 0] step=1390, skipped=0, lr=[7.333333333333334e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:24:33,115] [INFO] [timer.py:198:stop] epoch=0/micro_step=1390/global_step=1390, RunningAvgSamplesPerSec=2.9823588024095518, CurrSamplesPerSec=2.9259594593192317, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6053, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.93}
{'loss': 0.5219, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.93}
[2023-03-12 19:25:00,538] [INFO] [logging.py:75:log_dist] [Rank 0] step=1400, skipped=0, lr=[6.666666666666667e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:25:00,540] [INFO] [timer.py:198:stop] epoch=0/micro_step=1400/global_step=1400, RunningAvgSamplesPerSec=2.9820044213956716, CurrSamplesPerSec=2.5198366430326447, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6592, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.93}
{'eval_loss': 0.8172915577888489, 'eval_runtime': 6.0054, 'eval_samples_per_second': 16.652, 'eval_steps_per_second': 2.165, 'epoch': 0.93}
{'loss': 0.6258, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.94}
[2023-03-12 19:25:32,661] [INFO] [logging.py:75:log_dist] [Rank 0] step=1410, skipped=0, lr=[6e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:25:32,662] [INFO] [timer.py:198:stop] epoch=0/micro_step=1410/global_step=1410, RunningAvgSamplesPerSec=2.9827231519008195, CurrSamplesPerSec=2.6931739505995074, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7101, 'learning_rate': 6e-06, 'epoch': 0.94}
{'loss': 0.8682, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.94}
[2023-03-12 19:25:59,071] [INFO] [logging.py:75:log_dist] [Rank 0] step=1420, skipped=0, lr=[5.333333333333334e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:25:59,073] [INFO] [timer.py:198:stop] epoch=0/micro_step=1420/global_step=1420, RunningAvgSamplesPerSec=2.9831921134736707, CurrSamplesPerSec=3.049695656943558, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.8535, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.95}
{'eval_loss': 0.8173332214355469, 'eval_runtime': 6.2449, 'eval_samples_per_second': 16.013, 'eval_steps_per_second': 2.082, 'epoch': 0.95}
{'loss': 0.7398, 'learning_rate': 5e-06, 'epoch': 0.95}
[2023-03-12 19:26:31,673] [INFO] [logging.py:75:log_dist] [Rank 0] step=1430, skipped=0, lr=[4.666666666666667e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:26:31,685] [INFO] [timer.py:198:stop] epoch=0/micro_step=1430/global_step=1430, RunningAvgSamplesPerSec=2.983710673614999, CurrSamplesPerSec=3.066368654391968, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5605, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.95}
{'loss': 1.0861, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.96}
[2023-03-12 19:26:58,282] [INFO] [logging.py:75:log_dist] [Rank 0] step=1440, skipped=0, lr=[4.000000000000001e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:26:58,283] [INFO] [timer.py:198:stop] epoch=0/micro_step=1440/global_step=1440, RunningAvgSamplesPerSec=2.9840321508825256, CurrSamplesPerSec=3.2372321085991813, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7038, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.96}
{'eval_loss': 0.8172847628593445, 'eval_runtime': 5.8294, 'eval_samples_per_second': 17.155, 'eval_steps_per_second': 2.23, 'epoch': 0.96}
{'loss': 0.9137, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.96}
[2023-03-12 19:27:31,352] [INFO] [logging.py:75:log_dist] [Rank 0] step=1450, skipped=0, lr=[3.3333333333333333e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:27:31,364] [INFO] [timer.py:198:stop] epoch=0/micro_step=1450/global_step=1450, RunningAvgSamplesPerSec=2.983853340705314, CurrSamplesPerSec=3.099764402831896, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6922, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.97}
{'loss': 0.6913, 'learning_rate': 3e-06, 'epoch': 0.97}
[2023-03-12 19:27:57,940] [INFO] [logging.py:75:log_dist] [Rank 0] step=1460, skipped=0, lr=[2.666666666666667e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:27:57,941] [INFO] [timer.py:198:stop] epoch=0/micro_step=1460/global_step=1460, RunningAvgSamplesPerSec=2.984204808678133, CurrSamplesPerSec=3.078266538268074, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7587, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.97}
{'eval_loss': 0.8172411918640137, 'eval_runtime': 5.908, 'eval_samples_per_second': 16.926, 'eval_steps_per_second': 2.2, 'epoch': 0.97}
{'loss': 0.5566, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.98}
[2023-03-12 19:28:31,057] [INFO] [logging.py:75:log_dist] [Rank 0] step=1470, skipped=0, lr=[2.0000000000000003e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:28:31,058] [INFO] [timer.py:198:stop] epoch=0/micro_step=1470/global_step=1470, RunningAvgSamplesPerSec=2.984088117050804, CurrSamplesPerSec=3.0289690976732917, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.631, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.98}
{'loss': 0.5694, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.98}
[2023-03-12 19:28:57,738] [INFO] [logging.py:75:log_dist] [Rank 0] step=1480, skipped=0, lr=[1.3333333333333334e-06], mom=[[0.9, 0.999]]
[2023-03-12 19:28:57,740] [INFO] [timer.py:198:stop] epoch=0/micro_step=1480/global_step=1480, RunningAvgSamplesPerSec=2.984332965144601, CurrSamplesPerSec=3.0459251222589048, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.6529, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.99}
{'eval_loss': 0.8172479271888733, 'eval_runtime': 6.0277, 'eval_samples_per_second': 16.59, 'eval_steps_per_second': 2.157, 'epoch': 0.99}
{'loss': 0.8227, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.99}
[2023-03-12 19:29:30,433] [INFO] [logging.py:75:log_dist] [Rank 0] step=1490, skipped=0, lr=[6.666666666666667e-07], mom=[[0.9, 0.999]]
[2023-03-12 19:29:30,435] [INFO] [timer.py:198:stop] epoch=0/micro_step=1490/global_step=1490, RunningAvgSamplesPerSec=2.984623906822784, CurrSamplesPerSec=3.034291099198809, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.5699, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.99}
{'loss': 0.6423, 'learning_rate': 3.3333333333333335e-07, 'epoch': 1.0}
[2023-03-12 19:29:57,631] [INFO] [logging.py:75:log_dist] [Rank 0] step=1500, skipped=0, lr=[0.0], mom=[[0.9, 0.999]]
[2023-03-12 19:29:57,632] [INFO] [timer.py:198:stop] epoch=0/micro_step=1500/global_step=1500, RunningAvgSamplesPerSec=2.984481549318177, CurrSamplesPerSec=2.758670948413501, MemAllocated=0.0GB, MaxMemAllocated=1.11GB
{'loss': 0.7146, 'learning_rate': 0.0, 'epoch': 1.0}
{'eval_loss': 0.8172545433044434, 'eval_runtime': 6.2092, 'eval_samples_per_second': 16.105, 'eval_steps_per_second': 2.094, 'epoch': 1.0}
[2023-03-12 19:30:07,398] [INFO] [engine.py:3516:save_16bit_model] Saving model weights to /data1/s1930443/hf_models/checkpoint-1500/pytorch_model.bin
[2023-03-12 19:30:07,398] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving /data1/s1930443/hf_models/checkpoint-1500/pytorch_model.bin...
[2023-03-12 19:30:07,958] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved /data1/s1930443/hf_models/checkpoint-1500/pytorch_model.bin.
[2023-03-12 19:30:07,979] [INFO] [logging.py:75:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is begin to save!
[2023-03-12 19:30:08,026] [INFO] [logging.py:75:log_dist] [Rank 0] Saving model checkpoint: /data1/s1930443/hf_models/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-03-12 19:30:08,026] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving /data1/s1930443/hf_models/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-03-12 19:30:08,047] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved /data1/s1930443/hf_models/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-03-12 19:30:08,129] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving /data1/s1930443/hf_models/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-03-12 19:30:08,713] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved /data1/s1930443/hf_models/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-03-12 19:30:08,795] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved /data1/s1930443/hf_models/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-03-12 19:30:08,860] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step1500 is ready now!
{'train_runtime': 4520.2478, 'train_samples_per_second': 2.653, 'train_steps_per_second': 0.332, 'train_loss': 0.8561187580426534, 'epoch': 1.0}
[2023-03-12 19:31:21,782] [INFO] [logging.py:75:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is begin to save!
[2023-03-12 19:31:21,825] [INFO] [logging.py:75:log_dist] [Rank 0] Saving model checkpoint: /data1/s1930443/hf_models/checkpoint-final/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-03-12 19:31:21,826] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving /data1/s1930443/hf_models/checkpoint-final/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-03-12 19:31:21,885] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved /data1/s1930443/hf_models/checkpoint-final/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-03-12 19:31:21,926] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving /data1/s1930443/hf_models/checkpoint-final/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-03-12 19:31:22,637] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved /data1/s1930443/hf_models/checkpoint-final/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-03-12 19:31:22,700] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved /data1/s1930443/hf_models/checkpoint-final/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-03-12 19:31:22,705] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step1500 is ready now!
Successfully finished and closing now. Goodbye!Successfully finished and closing now. Goodbye!
Successfully finished and closing now. Goodbye!

[2023-03-12 19:31:26,370] [INFO] [engine.py:3516:save_16bit_model] Saving model weights to /data1/s1930443/hf_models/pytorch_model.bin
[2023-03-12 19:31:26,371] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving /data1/s1930443/hf_models/pytorch_model.bin...
[2023-03-12 19:31:26,882] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved /data1/s1930443/hf_models/pytorch_model.bin.
Successfully finished and closing now. Goodbye!
[2023-03-12 19:31:38,721] [INFO] [launch.py:350:main] Process 40407 exits successfully.
[2023-03-12 19:31:38,721] [INFO] [launch.py:350:main] Process 40406 exits successfully.
[2023-03-12 19:31:38,721] [INFO] [launch.py:350:main] Process 40405 exits successfully.
[2023-03-12 19:31:38,722] [INFO] [launch.py:350:main] Process 40404 exits successfully.
[/bin/bash] ## Script finished
[/bin/bash] ## Deactivating environment and close job.
